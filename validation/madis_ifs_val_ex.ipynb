{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book is to create new validation figures for windspeed from IFS with the madis mesonet QC final dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/kylabazlen/\")\n",
    "processing = importlib.import_module(\"2026_nvhackathon.validation.processing\")\n",
    "subset_grid_to_point_xy = processing.subset_grid_to_point_xy\n",
    "forecast_obs_merge = processing.forecast_obs_merge\n",
    "convert_1d_to_2d_latlon = processing.convert_1d_to_2d_latlon\n",
    "metrics = importlib.import_module(\"2026_nvhackathon.validation.metrics\")\n",
    "add_gof_stats = metrics.add_gof_stats\n",
    "\n",
    "plotting = importlib.import_module(\"2026_nvhackathon.validation.plotting\")\n",
    "confusion_matrix = plotting.confusion_matrix\n",
    "plot_confusion_matrix = plotting.plot_confusion_matrix\n",
    "\n",
    "configure_style = plotting.configure_style\n",
    "COLORS = plotting.COLORS\n",
    "MARKERS = plotting.MARKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = '/project/cowy-nvhackathon/cowy-wildfire/data/observations/cowy_madis_metar_mesonet_2024.nc'\n",
    "# ifs_paths = sorted(glob.glob(\"/gscratch/kylabazlen/nwp/ifs/yearly_datasets/*\"))\n",
    "ifs_paths = sorted(glob.glob(\"/project/cowy-nvhackathon/cowy-wildfire/data/nwp/ifs_yearly/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_340001/4066160720.py:5: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  ifs_ds = xr.open_dataset(ifs_paths[0]) #time, latitude, longitude diminsions\n"
     ]
    }
   ],
   "source": [
    "# Open the observations file\n",
    "obs_ds = xr.open_dataset(observations) #space, time diminsions\n",
    "\n",
    "# Open the first IFS file\n",
    "ifs_ds = xr.open_dataset(ifs_paths[0]) #time, latitude, longitude diminsions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop stations with all NA windspeed data\n",
    "has_data_mask = ~obs_ds['windspeed_10m'].isnull().all(dim='time')\n",
    "\n",
    "obs_ds_clean = obs_ds.sel(space=has_data_mask)\n",
    "\n",
    "print(f\"Original stations: {obs_ds.dims['space']}\")\n",
    "print(f\"Stations with data: {obs_ds_clean.dims['space']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re \n",
    "\n",
    "results = []\n",
    "mbe_records = []\n",
    "\n",
    "for fp in ifs_paths:\n",
    "    ifs_ds = xr.open_dataset(fp)\n",
    "\n",
    "    ds = convert_1d_to_2d_latlon(ds=ifs_ds)\n",
    "    ifs_subset = subset_grid_to_point_xy(ds=ds, point_ds=obs_ds_clean)\n",
    "    all_data_ifs = forecast_obs_merge(ds1=ifs_subset, ds2=obs_ds_clean, ds1_timevar=\"valid_time\", ds2_timevar=\"time\")\n",
    "    all_w_gof = add_gof_stats(ds=all_data_ifs, var1=\"ws_10\", var2=\"obs_windspeed_10m\")\n",
    "    results.append(all_w_gof)\n",
    "\n",
    "    # Extract filename and forecast hour\n",
    "    filename = Path(fp).stem\n",
    "    forecast_hour = int(re.search(r'_f(\\d+)', filename).group(1))\n",
    "    \n",
    "    \n",
    "    # Calculate mean GOF across stations\n",
    "    mean_mbe = all_w_gof['ws_10_vs_obs_windspeed_10m_MBE'].mean(dim='space').item()  # adjust 'station' to your actual dimension name\n",
    "    mean_rmse = all_w_gof['ws_10_vs_obs_windspeed_10m_RMSE'].mean(dim='space').item()  # adjust 'station' to your actual dimension name\n",
    "\n",
    "    mbe_records.append({\n",
    "        'file': Path(fp).stem,\n",
    "        'forecast_hr': forecast_hour,\n",
    "        'mean_mbe': mean_mbe,\n",
    "        'mean_rmse': mean_rmse\n",
    "\n",
    "    })\n",
    "    \n",
    "    ifs_ds.close()\n",
    "\n",
    "# Create DataFrame\n",
    "mbe_df = pd.DataFrame(mbe_records)\n",
    "print(mbe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mbe_df['forecast_hr'], mbe_df['mean_mbe'], marker='o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Forecast Hour')\n",
    "plt.ylabel('Mean MBE')\n",
    "plt.title('Mean Bias Error by Forecast Hour')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "mbe_records = []\n",
    "\n",
    "# Define wind speed bins (0-5, 5-10, 10-15, etc.)\n",
    "ws_bins = np.arange(0, 35, 5)  # Adjust upper limit as needed\n",
    "bin_labels = [f\"{ws_bins[i]}-{ws_bins[i+1]}\" for i in range(len(ws_bins)-1)]\n",
    "\n",
    "for fp in ifs_paths:\n",
    "    ifs_ds = xr.open_dataset(fp)\n",
    "    ds = convert_1d_to_2d_latlon(ds=ifs_ds)\n",
    "    ifs_subset = subset_grid_to_point_xy(ds=ds, point_ds=obs_ds)\n",
    "    all_data_ifs = forecast_obs_merge(ds1=ifs_subset, ds2=obs_ds, ds1_timevar=\"valid_time\", ds2_timevar=\"time\")\n",
    "    all_w_gof = add_gof_stats(ds=all_data_ifs, var1=\"ws_10\", var2=\"obs_windspeed_10m\")\n",
    "    results.append(all_w_gof)\n",
    "\n",
    "    # Extract filename and forecast hour\n",
    "    filename = Path(fp).stem\n",
    "    forecast_hour = int(re.search(r'_f(\\d+)', filename).group(1))\n",
    "\n",
    "    # Calculate mean GOF across stations (total)\n",
    "    mean_mbe = all_w_gof['ws_10_vs_obs_windspeed_10m_MBE'].mean(dim='space').item()\n",
    "    mean_rmse = all_w_gof['ws_10_vs_obs_windspeed_10m_RMSE'].mean(dim='space').item()\n",
    "\n",
    "    # Initialize record with total stats\n",
    "    record = {\n",
    "        'file': filename,\n",
    "        'forecast_hr': forecast_hour,\n",
    "        'mean_mbe_total': mean_mbe,\n",
    "        'mean_rmse_total': mean_rmse\n",
    "    }\n",
    "\n",
    "    # Get forecast and observed wind speed arrays\n",
    "    forecast_ws = all_data_ifs['ws_10'].values.flatten()\n",
    "    obs_ws = all_data_ifs['obs_windspeed_10m'].values.flatten()\n",
    "\n",
    "    # Remove NaN pairs\n",
    "    valid_mask = ~np.isnan(forecast_ws) & ~np.isnan(obs_ws)\n",
    "    forecast_ws_valid = forecast_ws[valid_mask]\n",
    "    obs_ws_valid = obs_ws[valid_mask]\n",
    "\n",
    "    # Calculate error\n",
    "    error = forecast_ws_valid - obs_ws_valid\n",
    "\n",
    "    # Bin by observed wind speed and calculate MBE/RMSE for each bin\n",
    "    bin_indices = np.digitize(obs_ws_valid, ws_bins) - 1  # -1 to make 0-indexed\n",
    "\n",
    "    for i, label in enumerate(bin_labels):\n",
    "        bin_mask = bin_indices == i\n",
    "        \n",
    "        if np.sum(bin_mask) > 0:\n",
    "            bin_errors = error[bin_mask]\n",
    "            bin_mbe = np.mean(bin_errors)\n",
    "            bin_rmse = np.sqrt(np.mean(bin_errors**2))\n",
    "            bin_count = np.sum(bin_mask)\n",
    "        else:\n",
    "            bin_mbe = np.nan\n",
    "            bin_rmse = np.nan\n",
    "            bin_count = 0\n",
    "\n",
    "        record[f'mbe_{label}'] = bin_mbe\n",
    "        record[f'rmse_{label}'] = bin_rmse\n",
    "        record[f'count_{label}'] = bin_count\n",
    "\n",
    "    mbe_records.append(record)\n",
    "    ifs_ds.close()\n",
    "\n",
    "# Create DataFrame\n",
    "mbe_df = pd.DataFrame(mbe_records)\n",
    "print(mbe_df)\n",
    "\n",
    "# Optional: Display column info\n",
    "print(\"\\nColumns:\", mbe_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "\n",
    "# Apply the style configuration\n",
    "configure_style()\n",
    "\n",
    "# Define the bin columns and labels\n",
    "bin_labels = ['0-5', '5-10', '10-15', '15-20', '20-25']\n",
    "mbe_columns = [f'rmse_{label}' for label in bin_labels]\n",
    "\n",
    "# Create reversed PuBuGn colormap (high to low)\n",
    "# Sample from 0.1-0.65 range to stay in saturated colors (avoid the light purple end)\n",
    "cmap = cm.PuBuGn_r\n",
    "colors = [cmap(0.1 + 0.55 * i / (len(bin_labels) - 1)) for i in range(len(bin_labels))]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each wind speed bin\n",
    "for i, (col, label) in enumerate(zip(mbe_columns, bin_labels)):\n",
    "    ax.plot(\n",
    "        mbe_df['forecast_hr'], \n",
    "        mbe_df[col], \n",
    "        marker=MARKERS[i], \n",
    "        color=colors[i], \n",
    "        label=f'{label} m/s',\n",
    "        linewidth=2,\n",
    "        markersize=5\n",
    "    )\n",
    "\n",
    "# Plot total MBE as a dashed black line\n",
    "ax.plot(\n",
    "    mbe_df['forecast_hr'], \n",
    "    mbe_df['mean_rmse_total'], \n",
    "    marker=MARKERS[5], \n",
    "    color='black', \n",
    "    label='All',\n",
    "    linewidth=2.5,\n",
    "    markersize=6,\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "# Add horizontal line at zero\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Forecast Hour')\n",
    "ax.set_ylabel('RMSE (m/s)')\n",
    "ax.set_title('IFS Wind Speed RMSE')\n",
    "\n",
    "# Set x-ticks to match forecast hours\n",
    "ax.set_xticks(mbe_df['forecast_hr'])\n",
    "\n",
    "# Legend on the right outside the plot\n",
    "ax.legend(\n",
    "    title='Observed Wind Speed', \n",
    "    loc='center left', \n",
    "    bbox_to_anchor=(1.02, 0.5),\n",
    "    framealpha=0.9\n",
    ")\n",
    "\n",
    "# Adjust layout to make room for legend\n",
    "fig.subplots_adjust(right=0.82)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Collect all observations and predictions across all forecast hours\n",
    "all_obs = []\n",
    "all_pred = []\n",
    "\n",
    "for result in results:\n",
    "    obs = result['obs_windspeed_10m'].values.ravel()\n",
    "    pred = result['ws_10'].values.ravel()\n",
    "    all_obs.append(obs)\n",
    "    all_pred.append(pred)\n",
    "\n",
    "# Concatenate into single arrays\n",
    "all_obs = np.concatenate(all_obs)\n",
    "all_pred = np.concatenate(all_pred)\n",
    "\n",
    "# Remove NaNs if present\n",
    "mask = ~np.isnan(all_obs) & ~np.isnan(all_pred)\n",
    "all_obs = all_obs[mask]\n",
    "all_pred = all_pred[mask]\n",
    "\n",
    "# Compute single confusion matrix\n",
    "threshold = 15\n",
    "cm_all = confusion_matrix(all_obs, all_pred, threshold=threshold)\n",
    "print(cm_all)\n",
    "\n",
    "# Plot it\n",
    "plot_confusion_matrix(cm_all, title=f\"Confusion Matrix (All Forecast Hours, threshold={threshold})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cowy-wildfire-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
